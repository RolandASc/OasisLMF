"""
Ground up loss (GUL) inputs
"""
__all__ = [
    'generate_gul_items',
    'load_gul_items',
    'write_coverages_file',
    'write_items_file',
    'write_gul_files',
    'write_gulsummaryxref_file'
]


import io
import itertools
import multiprocessing
import sys

import pandas as pd

from ..cmd.cleaners import as_path
from ..utils.concurrency import (
    multithread,
    Task,
)
from ..utils.exceptions import OasisException

from .profiles import combined_grouped_canonical_profile


def generate_gul_items(
    self,
    canexp_profile,
    canexp_df,
    keys_df,
    group_id='item_id'
):
    """
    Generates GUL items.

    :param canexp_profile: Canonical exposure profile
    :type canexp_profile: dict

    :param canexp_df: Canonical exposure dataframe
    :type canexp_df: pandas.DataFrame

    :param keys_df: Keys dataframe
    :type keys_df: pandas.DataFrame

    :param group_id: Column/field by which to group GUL items - default is `item_id`
    :type group_id: str
    """
    cep = canexp_profile

    cgcp = combined_grouped_canonical_profile(profiles=(cep,))

    if not cgcp:
        raise OasisException(
            'Canonical loc. profile is possibly missing FM term information: '
            'FM term definitions for TIV, limit, deductible, attachment and/or share.'
        )

    fm_levels = tuple(cgcp.keys())

    try:
        for df in [canexp_df, keys_df]:
            if not df.columns.contains('index'):
                df['index'] = pd.Series(data=range(len(df)))

        if not str(canexp_df['row_id'].dtype).startswith('int'):
            canexp_df['row_id'] = canexp_df['row_id'].astype(int)

        if not str(keys_df['locid'].dtype).startswith('int'):
            keys_df['locid'] = keys_df['locid'].astype(int)

        oed_acc_col_repl = [{'accnumber': 'accntnum'}]
        for repl in oed_acc_col_repl:
                canexp_df.rename(columns=repl, inplace=True)

        merged_df = pd.merge(canexp_df, keys_df, left_on='row_id', right_on='locid').drop_duplicates()
        merged_df['index'] = pd.Series(data=range(len(merged_df)), dtype=object)

        cov_level_id = fm_levels[0]

        tiv_terms = tuple(t for t in [cgcp[cov_level_id][gid].get('tiv') for gid in cgcp[cov_level_id]] if t)

        if not tiv_terms:
            raise OasisException('No TIV elements found in the canonical exposures profile - please check the canonical exposures (loc) profile')

        fm_terms = {
            tiv_tgid: {
                term_type: (
                    cgcp[cov_level_id][tiv_tgid][term_type]['ProfileElementName'].lower() if cgcp[cov_level_id][tiv_tgid].get(term_type) else None
                ) for term_type in ('deductible', 'deductiblemin', 'deductiblemax', 'limit', 'share',)
            } for tiv_tgid in cgcp[cov_level_id]
        }

        item_id = 0
        zero_tiv_items = 0
        def positive_tiv_elements(it): return (
            [t for t in tiv_terms if it.get(t['ProfileElementName'].lower()) and it[t['ProfileElementName'].lower()] > 0 and t['CoverageTypeID'] == it['coveragetypeid']]
            or [0]
        )
        
        for it, ptiv in itertools.chain((it, ptiv) for _, it in merged_df.iterrows() for it, ptiv in itertools.product([it],positive_tiv_elements(it))):
            if ptiv == 0:
                zero_tiv_items += 1
                continue

            item_id += 1
            it['item_id'] = item_id
            tiv_elm = ptiv['ProfileElementName'].lower()
            tiv = it[tiv_elm]
            tiv_tgid = ptiv['FMTermGroupID']

            yield {
                'item_id': item_id,
                'canexp_id': it['row_id'] - 1,
                'peril_id': it['perilid'],
                'coverage_type_id': it['coveragetypeid'],
                'coverage_id': item_id,
                'tiv_elm': tiv_elm,
                'tiv': tiv,
                'tiv_tgid': tiv_tgid,
                'ded_elm': fm_terms[tiv_tgid].get('deductible'),
                'ded_min_elm': fm_terms[tiv_tgid].get('deductiblemin'),
                'ded_max_elm': fm_terms[tiv_tgid].get('deductiblemax'),
                'lim_elm': fm_terms[tiv_tgid].get('limit'),
                'shr_elm': fm_terms[tiv_tgid].get('share'),
                'areaperil_id': it['areaperilid'],
                'vulnerability_id': it['vulnerabilityid'],
                'group_id': it[group_id],
                'summary_id': 1,
                'summaryset_id': 1
            }
    except (AttributeError, KeyError, IndexError, TypeError, ValueError) as e:
        raise OasisException(e)
    else:
        if zero_tiv_items == len(merged_df):
            raise OasisException('All canonical exposure items have zero TIVs - please check the canonical exposures (loc.) file')


def load_gul_items(self, canexp_profile, canexp_fp, keys_fp, group_id='item_id'):
    """
    Loads GUL items generated by ``generate_gul_items`` into a Pandas frame,
    with some post-processing.

    :param canexp_profile: Canonical exposure profile
    :type canexp_profile: dict

    :param canexp_fp: Canonical exposure file path
    :type canexp_fp: str

    :param keys_fp: Keys file path
    :type keys_fp: str
    """
    cep = canexp_profile

    try:
        with io.open(canexp_fp, 'r', encoding='utf-8') as cf, io.open(keys_fp, 'r', encoding='utf-8') as kf:
            canexp_df, keys_df = pd.read_csv(cf, float_precision='high'), pd.read_csv(kf, float_precision='high')

        if len(canexp_df) == 0:
            raise OasisException('No canonical exposure items found - please check the canonical exposure file')

        if len(keys_df) == 0:
            raise OasisException('No keys items found - please check the model exposure file')

        canexp_df = canexp_df.where(canexp_df.notnull(), None)
        canexp_df.columns = canexp_df.columns.str.lower()
        canexp_df['index'] = pd.Series(data=range(len(canexp_df)))

        keys_df = keys_df.where(keys_df.notnull(), None)
        keys_df.columns = keys_df.columns.str.lower()
        keys_df['index'] = pd.Series(data=range(len(keys_df)))

        gul_items_df = pd.DataFrame(data=generate_gul_items(cep, canexp_df, keys_df, group_id=group_id), dtype=object)
        gul_items_df['index'] = pd.Series(data=range(len(gul_items_df)))

        for col in gul_items_df.columns:
            if col.endswith('id'):
                gul_items_df[col] = gul_items_df[col].astype(int)
            elif col == 'tiv':
                gul_items_df[col] = gul_items_df[col].astype(float)
    except (IOError, MemoryError, OasisException, OSError, TypeError, ValueError) as e:
        raise OasisException(e)
        
    return gul_items_df, canexp_df


def write_items_file(self, gul_items_df, items_fp):
    """
    Writes an items file.
    """
    try:
        gul_items_df.to_csv(
            columns=['item_id', 'coverage_id', 'areaperil_id', 'vulnerability_id', 'group_id'],
            path_or_buf=items_fp,
            encoding='utf-8',
            chunksize=1000,
            index=False
        )
    except (IOError, OSError) as e:
        raise OasisException(e)

    return items_fp


def write_coverages_file(self, gul_items_df, coverages_fp):
    """
    Writes a coverages file.
    """
    try:
        gul_items_df.to_csv(
            columns=['coverage_id', 'tiv'],
            path_or_buf=coverages_fp,
            encoding='utf-8',
            chunksize=1000,
            index=False
        )
    except (IOError, OSError) as e:
        raise OasisException(e)

    return coverages_fp


def write_gulsummaryxref_file(self, gul_items_df, gulsummaryxref_fp):
    """
    Writes a gulsummaryxref file.
    """
    try:
        gul_items_df.to_csv(
            columns=['coverage_id', 'summary_id', 'summaryset_id'],
            path_or_buf=gulsummaryxref_fp,
            encoding='utf-8',
            chunksize=1000,
            index=False
        )
    except (IOError, OSError) as e:
        raise OasisException(e)

    return gulsummaryxref_fp


def write_gul_files(self, canexp_profile, canexp_fp, keys_fp, items_fp, coverages_fp, gulsummaryxref_fp):
    """
    Writes the standard Oasis GUL files, namely::

        items.csv
        coverages.csv
        gulsummaryxref.csv
    """
    if not (items_fp and coverages_fp and gulsummaryxref_fp):
        raise OasisException('At least one or more of the GUL file paths is missing - items, coverages and GUL summaryxref file paths are all required')

    cep = canexp_profile
    
    gul_items_df, _ = load_gul_items(cep, canexp_fp, keys_fp)

    gul_files = {
        'items': items_fp,
        'coverages': coverages_fp,
        'gulsummaryxref': gulsummaryxref_fp
    }

    concurrent_tasks = (
        Task(getattr(sys.modules[__name__], 'write_{}_file'.format(f)), args=(gul_items_df.copy(deep=True), gul_files[f],), key=f)
        for f in gul_files
    )
    num_ps = min(len(gul_files), multiprocessing.cpu_count())
    for _, _ in multithread(concurrent_tasks, pool_size=num_ps):
        pass

    return gul_files
